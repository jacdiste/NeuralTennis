{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VB49QaYrcKs"
      },
      "source": [
        "# **NeuralTennis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XOXr9Xpo8369",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf18451-f508-4200-ce45-d58243e21160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet torch torchvision opencv-python-headless matplotlib plotly albumentations scikit-learn ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b96TCl2E8936",
        "outputId": "e75377de-b1ea-4b32-aadd-82c4c6cd04ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TS0GZoyO9BGW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/NeuralTennis\"\n",
        "for sub in [\"input\", \"models\", \"output\"]:\n",
        "    os.makedirs(f\"{BASE_DIR}/{sub}\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99nyaYFs9Dd7",
        "outputId": "919ce5e4-3b29-44c9-cb20-1c1aaa6ce3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video loaded – resolution: 1920 × 1080\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "video_path = f\"{BASE_DIR}/input/4.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    raise IOError(f\"Cannot open {video_path}\")\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "if not ret:\n",
        "    raise IOError(\"Cannot read the first frame\")\n",
        "print(\"Video loaded – resolution:\", frame.shape[1], \"×\", frame.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def read_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "def save_video(output_video_frames, output_video_path):\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, 30, (output_video_frames[0].shape[1], output_video_frames[0].shape[0]))\n",
        "    for frame in output_video_frames:\n",
        "        out.write(frame)\n",
        "    out.release()\n",
        "    print(f\"Video saved to {output_video_path}\")\n"
      ],
      "metadata": {
        "id": "8tUf6gCQe-Sn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "!yolo task=detect mode=train model=yolov5xu.pt data=/content/drive/MyDrive/NeuralTennis/data/data.yaml epochs=100 imgsz=640 batch=8 patience=15  project=/content/drive/MyDrive/NeuralTennis/models/ball_training name=run"
      ],
      "metadata": {
        "id": "iUvZtBjAuh4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83029906-be47-4e4b-d3ef-bd516668616f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5xu.pt to 'yolov5xu.pt'...\n",
            "100% 186M/186M [00:01<00:00, 122MB/s]\n",
            "Ultralytics 8.3.168 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/NeuralTennis/data/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5xu.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/NeuralTennis/models/ball_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/NeuralTennis/models/ball_training/run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 19.4MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      8800  ultralytics.nn.modules.conv.Conv             [3, 80, 6, 2, 2]              \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  4    309120  ultralytics.nn.modules.block.C3              [160, 160, 4]                 \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  8   2259200  ultralytics.nn.modules.block.C3              [320, 320, 8]                 \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1 12  13125120  ultralytics.nn.modules.block.C3              [640, 640, 12]                \n",
            "  7                  -1  1   7375360  ultralytics.nn.modules.conv.Conv             [640, 1280, 3, 2]             \n",
            "  8                  -1  4  19676160  ultralytics.nn.modules.block.C3              [1280, 1280, 4]               \n",
            "  9                  -1  1   4099840  ultralytics.nn.modules.block.SPPF            [1280, 1280, 5]               \n",
            " 10                  -1  1    820480  ultralytics.nn.modules.conv.Conv             [1280, 640, 1, 1]             \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  4   5332480  ultralytics.nn.modules.block.C3              [1280, 640, 4, False]         \n",
            " 14                  -1  1    205440  ultralytics.nn.modules.conv.Conv             [640, 320, 1, 1]              \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  4   1335040  ultralytics.nn.modules.block.C3              [640, 320, 4, False]          \n",
            " 18                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  4   4922880  ultralytics.nn.modules.block.C3              [640, 640, 4, False]          \n",
            " 21                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  4  19676160  ultralytics.nn.modules.block.C3              [1280, 1280, 4, False]        \n",
            " 24        [17, 20, 23]  1  11022931  ultralytics.nn.modules.head.Detect           [1, [320, 640, 1280]]         \n",
            "YOLOv5x summary: 285 layers, 97,200,371 parameters, 97,200,355 gradients, 246.9 GFLOPs\n",
            "\n",
            "Transferred 817/823 items from pretrained weights\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 93.6MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.5±0.1 ms, read: 0.2±0.1 MB/s, size: 91.9 KB)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/NeuralTennis/data/train/labels.cache... 428 images, 2 backgrounds, 0 corrupt: 100% 428/428 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.6±0.4 ms, read: 18.2±26.1 MB/s, size: 83.0 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/NeuralTennis/data/valid/labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100% 100/100 [00:00<?, ?it/s]\n",
            "Plotting labels to /content/drive/MyDrive/NeuralTennis/models/ball_training/run/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 135 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/NeuralTennis/models/ball_training/run\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100      7.93G      3.463      37.39     0.9702          9        640: 100% 54/54 [00:35<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.18it/s]\n",
            "                   all        100        101       0.37      0.109     0.0863     0.0136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/100      8.59G      3.589      3.988      0.972          7        640: 100% 54/54 [00:35<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.65it/s]\n",
            "                   all        100        101          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/100      8.61G      3.889      3.049     0.9951          5        640: 100% 54/54 [00:44<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.84it/s]\n",
            "                   all        100        101   3.55e-05     0.0099   1.79e-05   3.59e-06\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/100       8.6G       3.49      2.545     0.9583          5        640: 100% 54/54 [00:44<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.84it/s]\n",
            "                   all        100        101      0.725     0.0099     0.0067    0.00268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/100      8.96G      3.521      2.799     0.9528          9        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.97it/s]\n",
            "                   all        100        101      0.222     0.0495      0.066     0.0184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/100      8.58G       3.35      2.432     0.9487          5        640: 100% 54/54 [00:56<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.78it/s]\n",
            "                   all        100        101      0.152     0.0792     0.0366    0.00616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/100      8.61G      3.439      2.522     0.9295          5        640: 100% 54/54 [00:44<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.47it/s]\n",
            "                   all        100        101      0.536      0.149      0.197      0.048\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      8/100      8.97G      3.361      2.518     0.9174          9        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:12<00:00,  1.74s/it]\n",
            "                   all        100        101          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      9/100      8.59G       3.22      2.412     0.9144          5        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.59it/s]\n",
            "                   all        100        101      0.514      0.272      0.289     0.0681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     10/100      8.96G        3.3      2.356     0.9322          8        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:11<00:00,  1.63s/it]\n",
            "                   all        100        101      0.342      0.208      0.145     0.0343\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     11/100      8.98G      3.116      2.357     0.9014          5        640: 100% 54/54 [00:44<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.81it/s]\n",
            "                   all        100        101      0.238      0.149      0.157     0.0389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     12/100      8.99G      3.247      2.476     0.9336         10        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.92it/s]\n",
            "                   all        100        101      0.539      0.327      0.369      0.112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     13/100      8.97G      3.294       2.34     0.9151          5        640: 100% 54/54 [00:54<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.22it/s]\n",
            "                   all        100        101      0.631      0.254      0.288     0.0605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     14/100      8.58G      3.285      2.352     0.9087          7        640: 100% 54/54 [00:43<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.81it/s]\n",
            "                   all        100        101      0.307     0.0891     0.0792     0.0229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     15/100      8.96G      3.107      2.321     0.9243          5        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.88it/s]\n",
            "                   all        100        101      0.702      0.303      0.295     0.0973\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     16/100      8.98G      3.205      2.377     0.9154          9        640: 100% 54/54 [00:43<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.63it/s]\n",
            "                   all        100        101      0.597      0.293      0.295     0.0676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     17/100      8.97G      3.138      2.178     0.9082          7        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.86it/s]\n",
            "                   all        100        101      0.625      0.297      0.319      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     18/100      8.96G      3.099      2.133     0.9001          6        640: 100% 54/54 [00:43<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.41it/s]\n",
            "                   all        100        101      0.704      0.376      0.409      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     19/100      8.95G      3.033       2.17     0.8981          5        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.88it/s]\n",
            "                   all        100        101      0.622      0.326      0.343     0.0944\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     20/100      8.98G      3.115      2.013     0.8878         12        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.87it/s]\n",
            "                   all        100        101      0.697      0.287      0.288     0.0742\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     21/100      8.97G      3.152      2.016     0.8971          5        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.30it/s]\n",
            "                   all        100        101      0.505      0.277      0.271     0.0773\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     22/100      8.58G      3.115      2.084     0.8951          8        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.88it/s]\n",
            "                   all        100        101      0.591      0.436      0.393     0.0902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     23/100      8.99G      3.153       2.04     0.9071          8        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.88it/s]\n",
            "                   all        100        101      0.604      0.396      0.393     0.0845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     24/100      8.97G      2.948       2.03     0.8841          5        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.35it/s]\n",
            "                   all        100        101      0.664      0.416      0.419      0.102\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     25/100      8.59G      2.922      1.952     0.8755          4        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.88it/s]\n",
            "                   all        100        101      0.697      0.319      0.373      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     26/100      8.59G      2.943      1.823     0.9039          7        640: 100% 54/54 [00:44<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.65it/s]\n",
            "                   all        100        101      0.376      0.208       0.22     0.0644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     27/100      8.99G      3.058      2.009     0.8942         10        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.82it/s]\n",
            "                   all        100        101      0.519      0.193      0.274     0.0748\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     28/100      8.98G      2.798      1.767      0.864          7        640: 100% 54/54 [00:43<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.49it/s]\n",
            "                   all        100        101      0.497      0.238      0.269      0.089\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     29/100       8.6G      2.998      1.848     0.8907          6        640: 100% 54/54 [00:44<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.81it/s]\n",
            "                   all        100        101      0.743      0.406      0.402     0.0983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     30/100      8.58G      2.831      1.882     0.8659          8        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.79it/s]\n",
            "                   all        100        101       0.56      0.436      0.425       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     31/100      8.98G       2.93      1.902     0.8834          8        640: 100% 54/54 [00:44<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.77it/s]\n",
            "                   all        100        101      0.667      0.416      0.426      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     32/100      8.96G      2.877      2.021     0.8846          6        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.80it/s]\n",
            "                   all        100        101      0.685      0.431      0.457      0.124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     33/100      8.58G      2.921      1.821     0.8784          8        640: 100% 54/54 [00:42<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.84it/s]\n",
            "                   all        100        101      0.606      0.386      0.388      0.102\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     34/100      8.58G      2.811      1.737     0.9025          5        640: 100% 54/54 [00:44<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.60it/s]\n",
            "                   all        100        101      0.518      0.376      0.314     0.0856\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     35/100      8.97G      2.865      1.768     0.9001          8        640: 100% 54/54 [00:42<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.88it/s]\n",
            "                   all        100        101      0.592      0.356      0.353      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     36/100      8.96G      2.749      1.745     0.8376          4        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.85it/s]\n",
            "                   all        100        101      0.648      0.416       0.42      0.117\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     37/100       8.6G      2.897      1.839     0.8803         12        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.73it/s]\n",
            "                   all        100        101      0.581      0.356      0.351     0.0912\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     38/100      8.58G      2.802      1.832      0.861         10        640: 100% 54/54 [00:42<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.87it/s]\n",
            "                   all        100        101      0.678      0.438      0.481      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     39/100      8.98G      2.754      1.582     0.8669          6        640: 100% 54/54 [00:44<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.65it/s]\n",
            "                   all        100        101      0.648      0.416      0.424      0.149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     40/100      8.97G      2.788      1.705     0.8653          2        640: 100% 54/54 [00:46<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.43it/s]\n",
            "                   all        100        101      0.545      0.317      0.359      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     41/100      8.59G      2.818      1.676     0.8632          8        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.79it/s]\n",
            "                   all        100        101      0.633      0.386      0.436      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     42/100      8.59G      2.742      1.758     0.8824          8        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.84it/s]\n",
            "                   all        100        101      0.714      0.436      0.402     0.0953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     43/100      8.98G      2.789      1.703     0.8826          6        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.87it/s]\n",
            "                   all        100        101      0.501      0.337      0.304     0.0843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     44/100      8.97G      2.702      1.617     0.8663          8        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.87it/s]\n",
            "                   all        100        101      0.447      0.304      0.319     0.0841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     45/100      8.61G      2.716      1.601     0.8512          9        640: 100% 54/54 [00:43<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.58it/s]\n",
            "                   all        100        101      0.629      0.455      0.418      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     46/100      8.95G      2.753        1.6     0.8715          7        640: 100% 54/54 [00:43<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.81it/s]\n",
            "                   all        100        101      0.493      0.366      0.355      0.116\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     47/100      8.99G      2.566      1.559     0.8712          8        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.79it/s]\n",
            "                   all        100        101      0.679      0.455      0.452      0.143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     48/100      8.98G      2.615      1.615     0.8657          9        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.21it/s]\n",
            "                   all        100        101      0.716      0.424       0.48      0.158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     49/100      8.96G      2.678      1.637     0.8659          7        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.66it/s]\n",
            "                   all        100        101      0.622      0.424       0.39       0.12\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     50/100      8.57G      2.651      1.541     0.8611          6        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.85it/s]\n",
            "                   all        100        101      0.609      0.386      0.362      0.109\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     51/100      8.99G      2.568      1.577     0.8614          3        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.89it/s]\n",
            "                   all        100        101      0.613      0.376      0.416     0.0955\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     52/100      8.98G      2.581      1.571      0.853          4        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.72it/s]\n",
            "                   all        100        101      0.681      0.466      0.477      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     53/100      8.59G      2.488      1.381     0.8517          5        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.85it/s]\n",
            "                   all        100        101      0.731       0.51      0.538       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     54/100      8.57G      2.581      1.464     0.8783          7        640: 100% 54/54 [00:44<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.84it/s]\n",
            "                   all        100        101      0.747      0.446      0.451      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     55/100      8.99G      2.538      1.519     0.8638         11        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.22it/s]\n",
            "                   all        100        101       0.66      0.481      0.489      0.155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     56/100      8.98G      2.566      1.492     0.8557          6        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.87it/s]\n",
            "                   all        100        101      0.657      0.485      0.476      0.141\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     57/100       8.6G      2.504       1.34     0.8417          6        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.32it/s]\n",
            "                   all        100        101      0.632      0.485      0.491       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     58/100      8.58G      2.656       1.51     0.8712          8        640: 100% 54/54 [00:42<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.87it/s]\n",
            "                   all        100        101      0.682       0.51      0.528      0.178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     59/100      8.99G      2.546      1.414     0.8595          5        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.83it/s]\n",
            "                   all        100        101      0.654      0.475      0.491      0.149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     60/100      8.96G      2.646      1.496     0.8669          5        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.33it/s]\n",
            "                   all        100        101      0.578      0.376      0.377      0.121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     61/100      8.61G      2.501      1.585     0.8634          5        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.83it/s]\n",
            "                   all        100        101      0.731      0.495      0.489      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     62/100      8.59G       2.42      1.374     0.8598          8        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.89it/s]\n",
            "                   all        100        101      0.623      0.436      0.444      0.143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     63/100      8.99G      2.423      1.456     0.8527          7        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.89it/s]\n",
            "                   all        100        101      0.755      0.446      0.501      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     64/100      8.98G      2.491      1.318     0.8613          8        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.88it/s]\n",
            "                   all        100        101      0.692      0.467      0.494      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     65/100       8.6G      2.603      1.449     0.8593          6        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.67it/s]\n",
            "                   all        100        101      0.715      0.472      0.558      0.175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     66/100      8.58G      2.387       1.31     0.8548          9        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.85it/s]\n",
            "                   all        100        101      0.605      0.485      0.484      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     67/100      8.61G      2.552      1.452     0.8693          4        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.90it/s]\n",
            "                   all        100        101      0.599      0.356        0.4      0.145\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     68/100      8.98G      2.532      1.498     0.8606         10        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.87it/s]\n",
            "                   all        100        101       0.73      0.505      0.557      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     69/100      8.96G      2.401      1.402     0.8419          5        640: 100% 54/54 [00:52<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.91it/s]\n",
            "                   all        100        101      0.697      0.479        0.5      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     70/100      8.95G      2.334      1.357     0.8558         11        640: 100% 54/54 [00:42<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.89it/s]\n",
            "                   all        100        101      0.633      0.444      0.497      0.175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     71/100      8.98G      2.407      1.257     0.8681          6        640: 100% 54/54 [00:42<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.76it/s]\n",
            "                   all        100        101      0.746      0.446      0.507      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     72/100      8.61G      2.356      1.208     0.8458          8        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.89it/s]\n",
            "                   all        100        101      0.746      0.485      0.505      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     73/100      8.97G       2.32      1.193     0.8437          6        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.69it/s]\n",
            "                   all        100        101       0.74      0.564      0.629      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     74/100      8.59G      2.284      1.194     0.8466          8        640: 100% 54/54 [00:52<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.89it/s]\n",
            "                   all        100        101      0.703      0.545      0.614      0.226\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     75/100      8.98G      2.341      1.188      0.842          8        640: 100% 54/54 [00:53<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.49it/s]\n",
            "                   all        100        101      0.786      0.564      0.635      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     76/100      8.98G      2.301      1.132      0.842          6        640: 100% 54/54 [00:53<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.91it/s]\n",
            "                   all        100        101      0.818      0.495      0.633      0.223\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     77/100      8.97G      2.243      1.181     0.8412          9        640: 100% 54/54 [00:37<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.92it/s]\n",
            "                   all        100        101      0.663      0.545      0.562      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     78/100      8.56G      2.486      1.261     0.8555          8        640: 100% 54/54 [00:42<00:00,  1.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.91it/s]\n",
            "                   all        100        101      0.715      0.455      0.486      0.146\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     79/100      8.99G      2.306      1.279     0.8501          9        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.36it/s]\n",
            "                   all        100        101      0.808      0.495      0.597      0.208\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     80/100      8.97G      2.365      1.164     0.8733          6        640: 100% 54/54 [00:42<00:00,  1.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.89it/s]\n",
            "                   all        100        101      0.789      0.515      0.628      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     81/100       8.6G      2.264      1.103     0.8666          8        640: 100% 54/54 [00:43<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.40it/s]\n",
            "                   all        100        101      0.824       0.51      0.631       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     82/100      8.58G       2.32      1.156     0.8492          9        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.89it/s]\n",
            "                   all        100        101      0.783      0.537      0.614      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     83/100      8.98G      2.303      1.096      0.858          8        640: 100% 54/54 [00:42<00:00,  1.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.87it/s]\n",
            "                   all        100        101      0.756      0.525      0.593      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     84/100      8.97G      2.259      1.242     0.8319         10        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.87it/s]\n",
            "                   all        100        101      0.634      0.497      0.551       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     85/100      8.59G      2.208      1.168     0.8463          5        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.16it/s]\n",
            "                   all        100        101      0.691      0.535      0.577       0.23\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     86/100      8.58G      2.244      1.153     0.8378         12        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  3.17it/s]\n",
            "                   all        100        101        0.8      0.505      0.622      0.223\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     87/100      8.98G      2.182      1.039     0.8341          9        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.83it/s]\n",
            "                   all        100        101       0.68      0.545       0.56      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     88/100      8.97G      2.299      1.217     0.8158          1        640: 100% 54/54 [00:43<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:05<00:00,  1.39it/s]\n",
            "                   all        100        101      0.659      0.518       0.56      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     89/100      8.59G        2.2      1.102      0.843         11        640: 100% 54/54 [00:42<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.83it/s]\n",
            "                   all        100        101      0.717      0.554      0.607      0.227\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     90/100      8.57G      2.275      1.136     0.8433          8        640: 100% 54/54 [00:46<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:01<00:00,  3.92it/s]\n",
            "                   all        100        101      0.732      0.545      0.576      0.223\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 75, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "90 epochs completed in 1.357 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/NeuralTennis/models/ball_training/run/weights/last.pt, 194.9MB\n",
            "Optimizer stripped from /content/drive/MyDrive/NeuralTennis/models/ball_training/run/weights/best.pt, 194.9MB\n",
            "\n",
            "Validating /content/drive/MyDrive/NeuralTennis/models/ball_training/run/weights/best.pt...\n",
            "Ultralytics 8.3.168 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv5x summary (fused): 150 layers, 97,153,571 parameters, 0 gradients, 246.0 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.98it/s]\n",
            "                   all        100        101      0.783      0.564      0.635      0.245\n",
            "Speed: 0.4ms preprocess, 14.7ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/NeuralTennis/models/ball_training/run\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Import e impostazioni\n",
        "import cv2, os, glob, math\n",
        "\n",
        "# Cartelle sul tuo Drive\n",
        "input_dir   = '/content/drive/MyDrive/NeuralTennis/input'\n",
        "output_dir  = '/content/drive/MyDrive/NeuralTennis/images_to_annotate'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Parametri\n",
        "total_target     = 50\n",
        "video_paths      = sorted(glob.glob(os.path.join(input_dir, '*.mp4')))\n",
        "num_videos       = len(video_paths)\n",
        "per_video_target = math.ceil(total_target / num_videos)\n",
        "\n",
        "global_saved = 0\n",
        "\n",
        "# 3. Loop su tutti i video, fermandosi a 50 frame totali\n",
        "for video_path in video_paths:\n",
        "    if global_saved >= total_target:\n",
        "        break\n",
        "\n",
        "    cap       = cv2.VideoCapture(video_path)\n",
        "    total     = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    step      = max(1, total // per_video_target)\n",
        "    basename  = os.path.splitext(os.path.basename(video_path))[0]\n",
        "\n",
        "    saved_in_vid = 0\n",
        "    frame_idx    = 0\n",
        "    while cap.isOpened() and saved_in_vid < per_video_target and global_saved < total_target:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_idx % step == 0:\n",
        "            fname = f'{basename}_frame_{saved_in_vid:02d}.jpg'\n",
        "            cv2.imwrite(os.path.join(output_dir, fname), frame)\n",
        "            saved_in_vid += 1\n",
        "            global_saved += 1\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f'Video {basename}: estratti {saved_in_vid} frame')\n",
        "\n",
        "print(f'Totale immagini estratte in {output_dir}: {global_saved}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzbP_KwB3Zkz",
        "outputId": "da129636-b58e-4068-d973-e227b4864602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Video 1: estratti 9 frame\n",
            "Video 2: estratti 9 frame\n",
            "Video 3: estratti 9 frame\n",
            "Video 4: estratti 9 frame\n",
            "Video 5: estratti 9 frame\n",
            "Video 6: estratti 5 frame\n",
            "Totale immagini estratte in /content/drive/MyDrive/NeuralTennis/images_to_annotate: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os, glob\n",
        "from pathlib import Path\n",
        "\n",
        "# Path to your images and your manually annotated JSONs\n",
        "img_dir    = '/content/drive/MyDrive/NeuralTennis/images_to_annotate'\n",
        "ann_dir    = img_dir  # immagini e JSON vivono nella stessa cartella\n",
        "\n",
        "# Loop sui 6 match (assumiamo i nomi 1_, 2_, …, 6_)\n",
        "for match_id in range(1, 7):\n",
        "    prefix     = f\"{match_id}_frame_\"\n",
        "    master_j   = Path(ann_dir) / f\"{prefix}00.json\"\n",
        "    if not master_j.exists():\n",
        "        print(f\"[WARN] Master JSON not found for match {match_id} → {master_j}\")\n",
        "        continue\n",
        "\n",
        "    # Carica il master JSON\n",
        "    with open(master_j, 'r') as f:\n",
        "        master_ann = json.load(f)\n",
        "\n",
        "    # Trova tutti i JPG di questo match\n",
        "    pattern = str(Path(img_dir) / f\"{prefix}*.jpg\")\n",
        "    for img_path in sorted(glob.glob(pattern)):\n",
        "        target_j = img_path.replace('.jpg', '.json')\n",
        "        # Se c’è già un JSON (p.es. perché lo hai corretto o perché hai rimosso i frame),\n",
        "        # lo salti\n",
        "        if os.path.exists(target_j):\n",
        "            continue\n",
        "\n",
        "        # Duplichi il master, aggiornando solo imagePath\n",
        "        new_ann = master_ann.copy()\n",
        "        new_ann['imagePath'] = os.path.basename(img_path)\n",
        "        # (height/width/liquid non cambiano perché tutti i frame hanno stesse dim.)\n",
        "        with open(target_j, 'w') as out:\n",
        "            json.dump(new_ann, out, indent=2)\n",
        "        print(f\"Created {os.path.basename(target_j)}\")\n",
        "\n",
        "print(\"Done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lzbbhIaBuDj",
        "outputId": "8c888e2b-5ffe-4e81-f549-19c6dcb4aa45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 1_frame_03.json\n",
            "Created 1_frame_05.json\n",
            "Created 2_frame_01.json\n",
            "Created 2_frame_04.json\n",
            "Created 2_frame_05.json\n",
            "Created 3_frame_01.json\n",
            "Created 3_frame_02.json\n",
            "Created 3_frame_03.json\n",
            "Created 3_frame_04.json\n",
            "Created 3_frame_05.json\n",
            "Created 3_frame_06.json\n",
            "Created 3_frame_07.json\n",
            "Created 3_frame_08.json\n",
            "Created 4_frame_04.json\n",
            "Created 5_frame_07.json\n",
            "Created 6_frame_01.json\n",
            "Created 6_frame_02.json\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def labelme_to_coco(labelme_dir: str, output_json: str):\n",
        "    \"\"\"\n",
        "    Convert all LabelMe JSON files in a directory to a single COCO Keypoints JSON.\n",
        "    Uses the imageWidth/imageHeight fields (1920x1080) to normalize later.\n",
        "    \"\"\"\n",
        "    coco = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": [{\n",
        "            \"id\": 1,\n",
        "            \"name\": \"tennis_court\",\n",
        "            \"keypoints\": [f\"kp{i}\" for i in range(14)],\n",
        "            \"skeleton\": []\n",
        "        }]\n",
        "    }\n",
        "    ann_id = 1\n",
        "    img_id = 1\n",
        "\n",
        "    for jm_file in sorted(Path(labelme_dir).glob(\"*.json\")):\n",
        "        data = json.load(open(jm_file))\n",
        "        filename = data['imagePath']\n",
        "        height = data['imageHeight']  # dovrebbe essere 1080\n",
        "        width  = data['imageWidth']   # dovrebbe essere 1920\n",
        "\n",
        "        coco[\"images\"].append({\n",
        "            \"id\": img_id,\n",
        "            \"file_name\": filename,\n",
        "            \"height\": height,\n",
        "            \"width\": width\n",
        "        })\n",
        "\n",
        "        kpts = [0] * (14 * 3)\n",
        "        for shape in data[\"shapes\"]:\n",
        "            idx = int(shape[\"label\"].replace(\"kp\", \"\"))\n",
        "            x, y = shape[\"points\"][0]\n",
        "            kpts[idx*3]   = x\n",
        "            kpts[idx*3+1] = y\n",
        "            kpts[idx*3+2] = 2\n",
        "\n",
        "        coco[\"annotations\"].append({\n",
        "            \"id\": ann_id,\n",
        "            \"image_id\": img_id,\n",
        "            \"category_id\": 1,\n",
        "            \"keypoints\": kpts,\n",
        "            \"num_keypoints\": sum(1 for v in kpts[2::3] if v>0),\n",
        "            \"bbox\": [0, 0, 0, 0],\n",
        "            \"area\": 0\n",
        "        })\n",
        "\n",
        "        ann_id += 1\n",
        "        img_id += 1\n",
        "\n",
        "    with open(output_json, \"w\") as f:\n",
        "        json.dump(coco, f)\n",
        "    print(f\"Saved COCO annotations to {output_json}\")\n",
        "\n",
        "# Usage:\n",
        "labelme_dir  = \"/content/drive/MyDrive/NeuralTennis/images_to_annotate\"\n",
        "output_json = \"/content/drive/MyDrive/NeuralTennis/court_keypoints_coco.json\"\n",
        "labelme_to_coco(labelme_dir, output_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WG9HcYvCIyf",
        "outputId": "f75bf5c5-7501-48c1-f82e-135c2a1c6774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved COCO annotations to /content/drive/MyDrive/NeuralTennis/court_keypoints_coco.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "from pathlib import Path\n",
        "\n",
        "ann_path = Path('/content/drive/MyDrive/NeuralTennis/court_keypoints_coco.json')\n",
        "img_dir  = Path('/content/drive/MyDrive/NeuralTennis/images_to_annotate')\n",
        "\n",
        "coco = json.loads(ann_path.read_text())\n",
        "img_ids = {img['id'] for img in coco['images']}\n",
        "ann_ids = {ann['id'] for ann in coco['annotations']}\n",
        "\n",
        "# 1) Counts\n",
        "assert len(coco['images']) == 48, f\"Attese 48 immagini, trovate {len(coco['images'])}\"\n",
        "assert len(coco['annotations']) == 48, f\"Attese 48 annotazioni, trovate {len(coco['annotations'])}\"\n",
        "\n",
        "# 2) File existence & per‑image 1 annotazione\n",
        "for img in coco['images']:\n",
        "    fp = img_dir / img['file_name']\n",
        "    assert fp.exists(), f\"Missing file {fp}\"\n",
        "    anns = [a for a in coco['annotations'] if a['image_id']==img['id']]\n",
        "    assert len(anns)==1, f\"Image {img['id']} ha {len(anns)} annotazioni\"\n",
        "\n",
        "# 3) Keypoints shape + validity\n",
        "for ann in coco['annotations']:\n",
        "    kps = ann['keypoints']\n",
        "    assert len(kps)==42, f\"Annotation {ann['id']} ha {len(kps)} keypoints, attesi 42\"\n",
        "    for i in range(0,42,3):\n",
        "        x,y,v = kps[i], kps[i+1], kps[i+2]\n",
        "        w,h = coco['images'][[im['id'] for im in coco['images']].index(ann['image_id'])]['width'], \\\n",
        "              coco['images'][[im['id'] for im in coco['images']].index(ann['image_id'])]['height']\n",
        "        assert 0 <= x <= w and 0 <= y <= h, f\"KP fuori immagine in ann {ann['id']}\"\n",
        "        assert v in (0,1,2), f\"Visibility errato ({v}) in ann {ann['id']}\"\n",
        "print(\"✅ COCO JSON OK!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33BUAsh0Gf04",
        "outputId": "08ec7098-49e1-434d-a6b5-9f2bcf6aa834"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ COCO JSON OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "class PlayerTracker:\n",
        "    def __init__(self,model_path):\n",
        "        self.model = YOLO(model_path)\n",
        "\n",
        "    def detect_frame(self,frame):\n",
        "        results = self.model.track(frame, persist=True)[0]\n",
        "        id_name_dict = results.names\n",
        "\n",
        "        player_dict = {}\n",
        "        for box in results.boxes:\n",
        "            track_id = int(box.id.tolist()[0])\n",
        "            result = box.xyxy.tolist()[0]\n",
        "            object_cls_id = box.cls.tolist()[0]\n",
        "            object_cls_name = id_name_dict[object_cls_id]\n",
        "            if object_cls_name == \"person\":\n",
        "                player_dict[track_id] = result\n",
        "\n",
        "        return player_dict\n",
        "\n",
        "    def draw_bboxes(self,video_frames, player_detections):\n",
        "        output_video_frames = []\n",
        "        for frame, player_dict in zip(video_frames, player_detections):\n",
        "            # Draw Bounding Boxes\n",
        "            for track_id, bbox in player_dict.items():\n",
        "                x1, y1, x2, y2 = bbox\n",
        "                cv2.putText(frame, f\"Player ID: {track_id}\",(int(bbox[0]),int(bbox[1] -10 )),cv2.FONT_HERSHEY_SIMPLEX, 0.9, (197, 197, 197), 2)\n",
        "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (197, 197, 197), 2)\n",
        "            output_video_frames.append(frame)\n",
        "\n",
        "        return output_video_frames\n",
        "\n",
        "\n",
        "class BallTracker:\n",
        "    def __init__(self,model_path):\n",
        "        self.model = YOLO(model_path)\n",
        "\n",
        "    def interpolate_ball_positions(self, ball_positions):\n",
        "        ball_positions = [x.get(1,[]) for x in ball_positions]\n",
        "\n",
        "        df_ball_positions = pd.DataFrame(ball_positions,columns=['x1','y1','x2','y2'])\n",
        "\n",
        "        df_ball_positions = df_ball_positions.interpolate()\n",
        "        df_ball_positions = df_ball_positions.bfill()\n",
        "\n",
        "        ball_positions = [{1:x} for x in df_ball_positions.to_numpy().tolist()]\n",
        "\n",
        "        return ball_positions\n",
        "\n",
        "\n",
        "    def detect_frame(self,frame):\n",
        "        results = self.model.predict(frame,conf=0.25)[0]\n",
        "\n",
        "        ball_dict = {}\n",
        "        for box in results.boxes:\n",
        "            result = box.xyxy.tolist()[0]\n",
        "            ball_dict[1] = result\n",
        "\n",
        "        return ball_dict\n",
        "\n",
        "\n",
        "    def draw_bboxes(self,video_frames, player_detections):\n",
        "        output_video_frames = []\n",
        "        for frame, ball_dict in zip(video_frames, player_detections):\n",
        "            # Draw Bounding Boxes\n",
        "            for track_id, bbox in ball_dict.items():\n",
        "                x1, y1, x2, y2 = bbox\n",
        "                cv2.putText(frame, f\"Ball ID: {track_id}\",(int(bbox[0]),int(bbox[1] -10 )),cv2.FONT_HERSHEY_SIMPLEX, 0.9, (96, 255, 168), 2)\n",
        "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (96, 255, 168), 2)\n",
        "            output_video_frames.append(frame)\n",
        "\n",
        "        return output_video_frames"
      ],
      "metadata": {
        "id": "VjhwmMJZpRjc"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    input_video_path = \"/content/drive/MyDrive/NeuralTennis/input/1.mp4\"\n",
        "    video_frames = read_video(input_video_path)\n",
        "\n",
        "    player_tracker = PlayerTracker(\"/content/drive/MyDrive/NeuralTennis/models/yolov8x.pt\")\n",
        "    player_detections = [player_tracker.detect_frame(frame) for frame in video_frames]\n",
        "    video_frames = player_tracker.draw_bboxes(video_frames, player_detections)\n",
        "\n",
        "    ball_tracker = BallTracker(\"/content/drive/MyDrive/NeuralTennis/models/ball_training/run/weights/best.pt\")\n",
        "    ball_detections = [ball_tracker.detect_frame(frame) for frame in video_frames]\n",
        "    ball_detections = ball_tracker.interpolate_ball_positions(ball_detections)\n",
        "    video_frames = ball_tracker.draw_bboxes(video_frames, ball_detections)\n",
        "\n",
        "    save_video(video_frames, \"/content/drive/MyDrive/NeuralTennis/output/1_out.mp4\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NZRjp9gjIa5",
        "outputId": "a1c186a7-056e-4a5e-efe5-71955cf9b647"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 8 persons, 2 tennis rackets, 2 chairs, 1 clock, 56.9ms\n",
            "Speed: 3.0ms preprocess, 56.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 tennis rackets, 2 chairs, 1 clock, 40.1ms\n",
            "Speed: 3.1ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 38.7ms\n",
            "Speed: 2.9ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 34.8ms\n",
            "Speed: 2.5ms preprocess, 34.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 33.2ms\n",
            "Speed: 2.9ms preprocess, 33.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 33.2ms\n",
            "Speed: 3.4ms preprocess, 33.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 37.0ms\n",
            "Speed: 2.6ms preprocess, 37.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 36.7ms\n",
            "Speed: 3.7ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 32.3ms\n",
            "Speed: 3.0ms preprocess, 32.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 31.2ms\n",
            "Speed: 2.8ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.3ms\n",
            "Speed: 2.9ms preprocess, 31.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.3ms\n",
            "Speed: 2.9ms preprocess, 31.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.1ms\n",
            "Speed: 2.5ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.0ms\n",
            "Speed: 2.8ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 2.7ms preprocess, 32.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 37.7ms\n",
            "Speed: 3.3ms preprocess, 37.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 33.2ms\n",
            "Speed: 3.3ms preprocess, 33.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 32.5ms\n",
            "Speed: 3.1ms preprocess, 32.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 33.3ms\n",
            "Speed: 3.1ms preprocess, 33.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 3.1ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 3.1ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 2.8ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 34.2ms\n",
            "Speed: 5.2ms preprocess, 34.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.6ms\n",
            "Speed: 2.9ms preprocess, 31.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 30.5ms\n",
            "Speed: 3.8ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.7ms\n",
            "Speed: 2.7ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.7ms\n",
            "Speed: 3.3ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 30.8ms\n",
            "Speed: 3.0ms preprocess, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.6ms\n",
            "Speed: 2.7ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 30.1ms\n",
            "Speed: 2.6ms preprocess, 30.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.1ms\n",
            "Speed: 2.7ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.3ms\n",
            "Speed: 3.1ms preprocess, 31.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 32.4ms\n",
            "Speed: 3.2ms preprocess, 32.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 tennis racket, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 2.9ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.5ms\n",
            "Speed: 2.9ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.6ms\n",
            "Speed: 2.9ms preprocess, 32.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.4ms\n",
            "Speed: 2.9ms preprocess, 32.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.6ms\n",
            "Speed: 3.1ms preprocess, 32.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.1ms preprocess, 32.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 30.9ms\n",
            "Speed: 3.6ms preprocess, 30.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 3.2ms preprocess, 32.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 30.9ms\n",
            "Speed: 3.0ms preprocess, 30.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.0ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 3.2ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 2.8ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 30.9ms\n",
            "Speed: 3.3ms preprocess, 30.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.4ms\n",
            "Speed: 3.5ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 31.2ms\n",
            "Speed: 3.0ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 31.2ms\n",
            "Speed: 3.3ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 3.1ms preprocess, 32.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.1ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 33.7ms\n",
            "Speed: 2.8ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 33.1ms\n",
            "Speed: 3.0ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 chairs, 1 clock, 32.5ms\n",
            "Speed: 2.9ms preprocess, 32.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 3.2ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.4ms\n",
            "Speed: 3.0ms preprocess, 32.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.0ms\n",
            "Speed: 3.8ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 3.2ms preprocess, 32.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.6ms\n",
            "Speed: 2.6ms preprocess, 31.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.2ms\n",
            "Speed: 2.7ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 2.9ms preprocess, 31.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.6ms\n",
            "Speed: 2.8ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 3.1ms preprocess, 31.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 30.7ms\n",
            "Speed: 3.2ms preprocess, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 2.7ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 3.4ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 2.5ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 2.9ms preprocess, 32.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 2.9ms preprocess, 31.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 2.9ms preprocess, 32.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 2.7ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 2.9ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 2.9ms preprocess, 31.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.2ms\n",
            "Speed: 3.3ms preprocess, 31.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 30.9ms\n",
            "Speed: 3.0ms preprocess, 30.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 3.1ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.2ms\n",
            "Speed: 3.2ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 2.8ms preprocess, 31.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.4ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.0ms\n",
            "Speed: 3.4ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 2.7ms preprocess, 32.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.2ms preprocess, 32.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.3ms\n",
            "Speed: 3.2ms preprocess, 31.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.4ms preprocess, 32.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 33.1ms\n",
            "Speed: 3.3ms preprocess, 33.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 3.0ms preprocess, 32.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.8ms\n",
            "Speed: 3.4ms preprocess, 32.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 3.0ms preprocess, 32.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 3.3ms preprocess, 32.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 3.5ms preprocess, 32.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 33.6ms\n",
            "Speed: 2.9ms preprocess, 33.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 33.7ms\n",
            "Speed: 3.0ms preprocess, 33.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 33.5ms\n",
            "Speed: 3.4ms preprocess, 33.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 33.4ms\n",
            "Speed: 3.0ms preprocess, 33.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 33.3ms\n",
            "Speed: 3.0ms preprocess, 33.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 31.2ms\n",
            "Speed: 3.3ms preprocess, 31.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 31.0ms\n",
            "Speed: 3.3ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 tennis racket, 2 chairs, 1 clock, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 30.2ms\n",
            "Speed: 2.9ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 chairs, 1 clock, 30.5ms\n",
            "Speed: 3.2ms preprocess, 30.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 4.2ms preprocess, 31.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.3ms\n",
            "Speed: 3.1ms preprocess, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 3.3ms preprocess, 31.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.3ms preprocess, 32.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 32.5ms\n",
            "Speed: 3.2ms preprocess, 32.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.2ms\n",
            "Speed: 5.7ms preprocess, 33.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.6ms\n",
            "Speed: 3.2ms preprocess, 32.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.5ms\n",
            "Speed: 3.3ms preprocess, 34.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.8ms\n",
            "Speed: 3.3ms preprocess, 32.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.1ms\n",
            "Speed: 3.9ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.2ms\n",
            "Speed: 5.5ms preprocess, 33.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.3ms\n",
            "Speed: 3.4ms preprocess, 32.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.6ms\n",
            "Speed: 3.5ms preprocess, 32.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.0ms\n",
            "Speed: 6.3ms preprocess, 33.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.5ms\n",
            "Speed: 3.1ms preprocess, 32.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.9ms\n",
            "Speed: 3.2ms preprocess, 32.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 34.1ms\n",
            "Speed: 3.4ms preprocess, 34.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 35.0ms\n",
            "Speed: 3.2ms preprocess, 35.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.3ms\n",
            "Speed: 3.4ms preprocess, 34.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.0ms\n",
            "Speed: 3.6ms preprocess, 34.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.6ms\n",
            "Speed: 3.3ms preprocess, 34.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.1ms\n",
            "Speed: 2.9ms preprocess, 34.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.2ms\n",
            "Speed: 2.9ms preprocess, 34.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.2ms\n",
            "Speed: 5.5ms preprocess, 34.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.3ms\n",
            "Speed: 3.1ms preprocess, 34.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.0ms\n",
            "Speed: 3.2ms preprocess, 34.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.4ms\n",
            "Speed: 2.9ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.3ms\n",
            "Speed: 3.0ms preprocess, 31.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.3ms\n",
            "Speed: 3.2ms preprocess, 32.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.4ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 2.5ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 38.0ms\n",
            "Speed: 3.4ms preprocess, 38.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 32.3ms\n",
            "Speed: 3.1ms preprocess, 32.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.1ms\n",
            "Speed: 3.6ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 tennis rackets, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 2.8ms preprocess, 32.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 30.7ms\n",
            "Speed: 3.1ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 32.6ms\n",
            "Speed: 2.9ms preprocess, 32.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 3.1ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.3ms\n",
            "Speed: 3.4ms preprocess, 32.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.9ms\n",
            "Speed: 3.1ms preprocess, 32.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 32.7ms\n",
            "Speed: 3.2ms preprocess, 32.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.0ms\n",
            "Speed: 2.8ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.1ms\n",
            "Speed: 3.3ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.3ms\n",
            "Speed: 3.0ms preprocess, 33.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 2.8ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 3.5ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.6ms\n",
            "Speed: 3.2ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 2.7ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 31.0ms\n",
            "Speed: 3.9ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 4.0ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 3.0ms preprocess, 31.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 31.6ms\n",
            "Speed: 3.4ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 31.6ms\n",
            "Speed: 3.1ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.2ms\n",
            "Speed: 3.8ms preprocess, 34.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.3ms\n",
            "Speed: 3.2ms preprocess, 34.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.8ms\n",
            "Speed: 3.2ms preprocess, 34.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.8ms\n",
            "Speed: 4.5ms preprocess, 34.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 34.6ms\n",
            "Speed: 2.9ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 3.0ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 2.7ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 3.4ms preprocess, 31.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 3.5ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.2ms\n",
            "Speed: 3.2ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.0ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.6ms\n",
            "Speed: 4.2ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 3.3ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.3ms preprocess, 32.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.3ms\n",
            "Speed: 3.0ms preprocess, 32.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.1ms\n",
            "Speed: 3.4ms preprocess, 33.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.4ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.0ms\n",
            "Speed: 3.3ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.5ms\n",
            "Speed: 3.4ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.2ms\n",
            "Speed: 2.9ms preprocess, 31.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 2.7ms preprocess, 32.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 3.1ms preprocess, 32.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.5ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.3ms\n",
            "Speed: 3.1ms preprocess, 32.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.3ms\n",
            "Speed: 3.3ms preprocess, 31.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 3.5ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 5.2ms preprocess, 32.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 30.7ms\n",
            "Speed: 3.5ms preprocess, 30.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 3.9ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.5ms\n",
            "Speed: 2.9ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.3ms\n",
            "Speed: 4.3ms preprocess, 32.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.2ms\n",
            "Speed: 2.7ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 3.5ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 32.9ms\n",
            "Speed: 3.5ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 33.3ms\n",
            "Speed: 3.8ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 33.3ms\n",
            "Speed: 2.9ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 34.2ms\n",
            "Speed: 3.0ms preprocess, 34.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 33.7ms\n",
            "Speed: 3.5ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 32.6ms\n",
            "Speed: 2.8ms preprocess, 32.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 tennis racket, 2 chairs, 1 clock, 32.2ms\n",
            "Speed: 3.1ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 30.9ms\n",
            "Speed: 4.5ms preprocess, 30.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.1ms\n",
            "Speed: 2.8ms preprocess, 32.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.6ms\n",
            "Speed: 2.8ms preprocess, 31.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 32.0ms\n",
            "Speed: 3.3ms preprocess, 32.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 2.9ms preprocess, 31.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 chairs, 1 clock, 31.9ms\n",
            "Speed: 4.0ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 46.5ms\n",
            "Speed: 2.4ms preprocess, 46.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.8ms\n",
            "Speed: 2.9ms preprocess, 41.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.6ms\n",
            "Speed: 2.9ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.8ms\n",
            "Speed: 2.8ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.6ms\n",
            "Speed: 3.2ms preprocess, 41.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.4ms\n",
            "Speed: 2.8ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.6ms\n",
            "Speed: 2.8ms preprocess, 42.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.5ms\n",
            "Speed: 2.9ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.0ms\n",
            "Speed: 3.2ms preprocess, 42.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.5ms\n",
            "Speed: 3.3ms preprocess, 40.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.8ms\n",
            "Speed: 3.1ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.3ms\n",
            "Speed: 2.8ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.1ms\n",
            "Speed: 3.4ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.0ms\n",
            "Speed: 2.7ms preprocess, 42.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.8ms\n",
            "Speed: 3.3ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.6ms\n",
            "Speed: 3.7ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.8ms\n",
            "Speed: 3.4ms preprocess, 41.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.3ms\n",
            "Speed: 3.5ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.9ms\n",
            "Speed: 3.9ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.1ms\n",
            "Speed: 4.3ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.6ms\n",
            "Speed: 2.7ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.3ms\n",
            "Speed: 3.5ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.8ms\n",
            "Speed: 3.3ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.0ms\n",
            "Speed: 3.1ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.5ms\n",
            "Speed: 2.4ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.4ms\n",
            "Speed: 3.2ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.5ms\n",
            "Speed: 3.3ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.5ms\n",
            "Speed: 2.9ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.1ms\n",
            "Speed: 3.2ms preprocess, 42.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.0ms\n",
            "Speed: 4.4ms preprocess, 40.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.2ms\n",
            "Speed: 2.9ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.4ms\n",
            "Speed: 2.6ms preprocess, 42.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.0ms\n",
            "Speed: 4.3ms preprocess, 40.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 43.1ms\n",
            "Speed: 3.4ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.4ms\n",
            "Speed: 2.7ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.6ms\n",
            "Speed: 3.0ms preprocess, 41.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.3ms\n",
            "Speed: 3.3ms preprocess, 42.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.8ms\n",
            "Speed: 4.0ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.8ms\n",
            "Speed: 3.2ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.3ms\n",
            "Speed: 2.7ms preprocess, 39.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.7ms\n",
            "Speed: 3.5ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.5ms\n",
            "Speed: 3.1ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.6ms\n",
            "Speed: 3.0ms preprocess, 39.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.1ms\n",
            "Speed: 3.2ms preprocess, 42.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.1ms\n",
            "Speed: 2.9ms preprocess, 41.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.9ms\n",
            "Speed: 3.1ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.5ms\n",
            "Speed: 3.0ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.7ms\n",
            "Speed: 3.0ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.2ms\n",
            "Speed: 2.8ms preprocess, 41.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.5ms\n",
            "Speed: 2.7ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.7ms\n",
            "Speed: 2.9ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.8ms\n",
            "Speed: 2.9ms preprocess, 41.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.8ms\n",
            "Speed: 2.9ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.1ms\n",
            "Speed: 2.9ms preprocess, 41.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.1ms\n",
            "Speed: 3.3ms preprocess, 41.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.7ms\n",
            "Speed: 3.6ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.3ms\n",
            "Speed: 3.0ms preprocess, 42.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.3ms\n",
            "Speed: 3.3ms preprocess, 39.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 44.0ms\n",
            "Speed: 3.4ms preprocess, 44.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.7ms\n",
            "Speed: 3.6ms preprocess, 39.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.9ms\n",
            "Speed: 3.5ms preprocess, 40.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.6ms\n",
            "Speed: 3.0ms preprocess, 42.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.8ms\n",
            "Speed: 3.0ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.2ms\n",
            "Speed: 2.9ms preprocess, 42.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.8ms\n",
            "Speed: 3.0ms preprocess, 39.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.9ms\n",
            "Speed: 3.0ms preprocess, 41.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.9ms\n",
            "Speed: 3.2ms preprocess, 41.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.9ms\n",
            "Speed: 3.0ms preprocess, 40.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.7ms\n",
            "Speed: 2.9ms preprocess, 39.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.5ms\n",
            "Speed: 2.9ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.1ms\n",
            "Speed: 2.9ms preprocess, 42.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.1ms\n",
            "Speed: 2.9ms preprocess, 41.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.8ms\n",
            "Speed: 4.8ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.4ms\n",
            "Speed: 3.1ms preprocess, 40.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.8ms\n",
            "Speed: 3.0ms preprocess, 41.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.8ms\n",
            "Speed: 3.3ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.0ms\n",
            "Speed: 3.7ms preprocess, 42.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.3ms\n",
            "Speed: 3.0ms preprocess, 40.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.1ms\n",
            "Speed: 3.4ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.7ms\n",
            "Speed: 3.3ms preprocess, 41.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.0ms\n",
            "Speed: 3.1ms preprocess, 40.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.7ms\n",
            "Speed: 3.3ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 38.5ms\n",
            "Speed: 5.4ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.8ms\n",
            "Speed: 3.5ms preprocess, 41.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 38.2ms\n",
            "Speed: 2.9ms preprocess, 38.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.1ms\n",
            "Speed: 3.1ms preprocess, 41.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.6ms\n",
            "Speed: 3.0ms preprocess, 40.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 38.9ms\n",
            "Speed: 3.5ms preprocess, 38.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.2ms\n",
            "Speed: 6.8ms preprocess, 40.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.7ms\n",
            "Speed: 3.2ms preprocess, 39.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.9ms\n",
            "Speed: 3.0ms preprocess, 40.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.3ms\n",
            "Speed: 3.1ms preprocess, 39.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.8ms\n",
            "Speed: 3.0ms preprocess, 42.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.5ms\n",
            "Speed: 3.0ms preprocess, 40.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.2ms\n",
            "Speed: 3.0ms preprocess, 41.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.1ms\n",
            "Speed: 2.8ms preprocess, 41.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.0ms\n",
            "Speed: 2.7ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 43.1ms\n",
            "Speed: 2.7ms preprocess, 43.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.8ms\n",
            "Speed: 2.9ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.8ms\n",
            "Speed: 2.8ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.2ms\n",
            "Speed: 2.8ms preprocess, 42.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.0ms\n",
            "Speed: 2.9ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.7ms\n",
            "Speed: 4.2ms preprocess, 42.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.6ms\n",
            "Speed: 3.2ms preprocess, 40.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.7ms\n",
            "Speed: 3.0ms preprocess, 40.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.3ms\n",
            "Speed: 5.9ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.5ms\n",
            "Speed: 2.9ms preprocess, 39.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.9ms\n",
            "Speed: 3.1ms preprocess, 42.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.5ms\n",
            "Speed: 3.0ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.5ms\n",
            "Speed: 2.9ms preprocess, 42.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.2ms\n",
            "Speed: 2.8ms preprocess, 42.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.0ms\n",
            "Speed: 2.8ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.0ms\n",
            "Speed: 2.7ms preprocess, 42.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.8ms\n",
            "Speed: 2.7ms preprocess, 39.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.6ms\n",
            "Speed: 2.8ms preprocess, 40.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 43.8ms\n",
            "Speed: 2.8ms preprocess, 43.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 38.4ms\n",
            "Speed: 3.4ms preprocess, 38.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.1ms\n",
            "Speed: 2.9ms preprocess, 40.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.3ms\n",
            "Speed: 3.1ms preprocess, 40.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.8ms\n",
            "Speed: 3.0ms preprocess, 41.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.0ms\n",
            "Speed: 3.2ms preprocess, 39.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.3ms\n",
            "Speed: 3.0ms preprocess, 42.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.9ms\n",
            "Speed: 2.9ms preprocess, 40.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.0ms\n",
            "Speed: 3.2ms preprocess, 42.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 38.8ms\n",
            "Speed: 2.9ms preprocess, 38.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.7ms\n",
            "Speed: 3.1ms preprocess, 42.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.4ms\n",
            "Speed: 3.0ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.7ms\n",
            "Speed: 3.3ms preprocess, 40.7ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 38.6ms\n",
            "Speed: 3.1ms preprocess, 38.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 43.1ms\n",
            "Speed: 3.2ms preprocess, 43.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.1ms\n",
            "Speed: 3.2ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.6ms\n",
            "Speed: 2.9ms preprocess, 41.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.8ms\n",
            "Speed: 2.8ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.9ms\n",
            "Speed: 3.3ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.3ms\n",
            "Speed: 3.9ms preprocess, 39.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.7ms\n",
            "Speed: 3.9ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.6ms\n",
            "Speed: 3.5ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.6ms\n",
            "Speed: 2.8ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.7ms\n",
            "Speed: 5.8ms preprocess, 41.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.6ms\n",
            "Speed: 3.2ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.3ms\n",
            "Speed: 3.2ms preprocess, 42.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.1ms\n",
            "Speed: 3.1ms preprocess, 40.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.8ms\n",
            "Speed: 3.2ms preprocess, 40.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.8ms\n",
            "Speed: 2.9ms preprocess, 41.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.1ms\n",
            "Speed: 3.6ms preprocess, 39.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.7ms\n",
            "Speed: 4.1ms preprocess, 41.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.3ms\n",
            "Speed: 3.0ms preprocess, 39.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.6ms\n",
            "Speed: 4.5ms preprocess, 41.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 38.2ms\n",
            "Speed: 4.0ms preprocess, 38.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.1ms\n",
            "Speed: 3.3ms preprocess, 42.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.6ms\n",
            "Speed: 3.5ms preprocess, 40.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.0ms\n",
            "Speed: 3.2ms preprocess, 40.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.2ms\n",
            "Speed: 3.0ms preprocess, 41.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.4ms\n",
            "Speed: 3.7ms preprocess, 39.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.2ms\n",
            "Speed: 2.8ms preprocess, 42.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.4ms\n",
            "Speed: 3.2ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.5ms\n",
            "Speed: 3.7ms preprocess, 40.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.2ms\n",
            "Speed: 2.6ms preprocess, 42.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.7ms\n",
            "Speed: 2.9ms preprocess, 39.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 42.3ms\n",
            "Speed: 3.2ms preprocess, 42.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.1ms\n",
            "Speed: 3.6ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.0ms\n",
            "Speed: 3.1ms preprocess, 41.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.5ms\n",
            "Speed: 3.2ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.7ms\n",
            "Speed: 3.1ms preprocess, 39.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.4ms\n",
            "Speed: 3.2ms preprocess, 42.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.1ms\n",
            "Speed: 3.0ms preprocess, 40.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.7ms\n",
            "Speed: 2.9ms preprocess, 41.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.7ms\n",
            "Speed: 2.9ms preprocess, 41.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.3ms\n",
            "Speed: 2.9ms preprocess, 39.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.3ms\n",
            "Speed: 3.4ms preprocess, 42.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.9ms\n",
            "Speed: 3.1ms preprocess, 39.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.7ms\n",
            "Speed: 3.0ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.7ms\n",
            "Speed: 2.9ms preprocess, 41.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.8ms\n",
            "Speed: 3.5ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.3ms\n",
            "Speed: 3.1ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.4ms\n",
            "Speed: 3.5ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.6ms\n",
            "Speed: 3.2ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.6ms\n",
            "Speed: 4.4ms preprocess, 41.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.7ms\n",
            "Speed: 3.0ms preprocess, 39.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.0ms\n",
            "Speed: 3.1ms preprocess, 42.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.7ms\n",
            "Speed: 2.7ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.6ms\n",
            "Speed: 3.4ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.6ms\n",
            "Speed: 2.7ms preprocess, 41.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 38.9ms\n",
            "Speed: 3.3ms preprocess, 38.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.2ms\n",
            "Speed: 3.7ms preprocess, 41.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.4ms\n",
            "Speed: 3.0ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.7ms\n",
            "Speed: 3.0ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.1ms\n",
            "Speed: 3.0ms preprocess, 42.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.9ms\n",
            "Speed: 3.1ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.8ms\n",
            "Speed: 2.9ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.2ms\n",
            "Speed: 3.1ms preprocess, 42.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.6ms\n",
            "Speed: 3.1ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.6ms\n",
            "Speed: 3.4ms preprocess, 41.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.2ms\n",
            "Speed: 3.1ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.6ms\n",
            "Speed: 2.8ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.6ms\n",
            "Speed: 3.8ms preprocess, 42.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.8ms\n",
            "Speed: 2.8ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.8ms\n",
            "Speed: 4.3ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.4ms\n",
            "Speed: 3.5ms preprocess, 41.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.1ms\n",
            "Speed: 4.2ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.9ms\n",
            "Speed: 3.7ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.2ms\n",
            "Speed: 2.9ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.6ms\n",
            "Speed: 3.0ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.2ms\n",
            "Speed: 2.9ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.4ms\n",
            "Speed: 3.1ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 41.2ms\n",
            "Speed: 3.4ms preprocess, 41.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 40.2ms\n",
            "Speed: 3.8ms preprocess, 40.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.9ms\n",
            "Speed: 2.9ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.3ms\n",
            "Speed: 3.9ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tennis ball, 39.5ms\n",
            "Speed: 3.0ms preprocess, 39.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.0ms\n",
            "Speed: 3.0ms preprocess, 42.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 41.3ms\n",
            "Speed: 2.8ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.4ms\n",
            "Speed: 3.0ms preprocess, 39.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.3ms\n",
            "Speed: 3.6ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.8ms\n",
            "Speed: 2.9ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video saved to /content/drive/MyDrive/NeuralTennis/output/1_out.mp4\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}